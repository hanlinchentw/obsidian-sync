# End-To-End Arguments in System Design

### Summary
The end-to-end argument, a principle for placing functions in layered systems, shows that correctness can be ensured by end-to-end checks and retries, while low-level implementations serve mainly for performance enhancements.
### Important points
1. Low-level mechanisms cannot guarantee correctness, but they can improve performance by reducing error frequency. True correctness requires end-to-end checks and retries at the application level.
	<u>_Justification_:</u> This is important because the file transfer example shows that many threats exist at different layers, including disk, memory, software, network, and crashes. While low-level mechanisms help, they cannot cover all threats and require significant engineering effort. An end-to-end checksum and retry provide correctness at minimal cost. In addition, since low-level systems are shared across applications, forcing certain features there can burden applications that do not need them. Also, issues such as duplicate suppression and encryption follow the same principle as data correctness: they are better implemented at the application layer, since only the application has sufficient context to handle them effectively. However, if low-level functions are unreliable or the error rate is not negligible, end-to-end retries may loop excessively. In this case, low-level mechanisms are still necessary—not for guaranteeing correctness, but for providing a sufficiently reliable environment on which application-level optimizations can build.
2. The "true" ends vary with the application. What’s useful for one case (e.g., live conversation) may harm another (e.g., recorded messages). 
	<u>_Justification_:</u>  This is important because it prevents misapplication of the principle. It shows that the argument is a guideline rather than a rigid rule, forcing designers to consider the application context, such as latency versus accuracy, rather than blindly enforcing reliability at one layer. It encourages nuanced engineering decisions that fit the actual end requirements instead of applying a one-size-fits-all solution.
3. History shows repeated rediscovery, indicating that end-to-end arguments is a general principle. It keeps reappearing in different domains: networking, file storage, banking audits, OS kernels, even RISC architecture.
	<u>_Justification_:</u> This is important because it demonstrates the generality of the principle: correctness belongs at the endpoints in any layered system. Historical failures, such as corrupted tape systems or network gateways, show the cost of ignoring it. It also provides a unifying way to think across fields — whether in networking, operating systems, or storage, the same principle applies. Finally, it reinforces that the end-to-end argument is not just theoretical but solves practical, recurring problems in real-world systems.
### Comments/Questions
1. My past work experience has mostly been at the application layer, but I’ve often faced similar situations that require careful consideration. In practice, we emphasize error-handling at the right level. For instance, if we have a network module and a client module that uses it, then the network module should have its own error-handling strategy, while the client module should have its own as well. Errors that can be resolved within the network module should be contained there, and only those requiring client attention should be passed up. Another example, when designing retry mechanisms, the client side may not always want to retry automatically when errors happen. Users might have concerns about network traffic usage, or it may be better simply to display an error message and let them check their own network environment. Blindly retrying may not solve the real issue and could instead waste bandwidth or other resources. Overall, this reflects the same philosophy as the end-to-end argument: in layered systems, functions should be handled at the layers most suited to the application’s context.
2. In the recent boom of AI, one question has always concerned me: how can we ensure that prompts are not altered by any entities in the AI pipeline, such as the model provider, cloud service, or interface? Building on a zero-trust perspective, we should not blindly assume that AI systems or the entities operating them are benign. Instead, we must design with the possibility of malicious behavior in mind. This means that critical safeguards, such as encryption and decryption, should remain at the endpoints (hosts), not within intermediate layers of the pipeline. In the future, when AI systems begin handling highly sensitive personal information, we may need to avoid exposing data in plain form altogether. For example, we could employ asymmetric cryptographic techniques—such as public-key encryption or secure hashing (e.g., SHA-256)—to ensure that sensitive inputs remain protected, even while interacting with AI services.

---

This version keeps your **zero-trust framing**, ties it explicitly to the **end-to-end argument**, and flows into the **forward-looking point about cryptographic protection**.

Would you like me to make this more **concise** (like a strong one-paragraph reflection for a review), or keep it as a **longer, structured comment** with clear sections?
### Citation
1. Saltzer, J. H., Reed, D. P., & Clark, D. D. (1984). _End-to-end arguments in system design_. ACM Transactions on Computer Systems, 2(4), 277–288. https://doi.org/10.1145/357401.357402